#
# This file is autogenerated by pip-compile with Python 3.10
# by the following command:
#
#    pip-compile requirements/requirements.in
#
--extra-index-url https://download.pytorch.org/whl/cu121

aiohttp==3.9.5
    # via vllm
aiosignal==1.3.1
    # via
    #   aiohttp
    #   ray
annotated-types==0.6.0
    # via pydantic
anyio==3.7.1
    # via
    #   httpcore
    #   openai
    #   starlette
    #   watchfiles
async-timeout==4.0.3
    # via aiohttp
attrs==23.1.0
    # via
    #   aiohttp
    #   jsonschema
    #   referencing
blis==0.7.11
    # via thinc
cachetools==5.3.3
    # via -r requirements/requirements.in
catalogue==2.0.10
    # via
    #   spacy
    #   srsly
    #   thinc
certifi==2023.11.17
    # via
    #   httpcore
    #   httpx
    #   requests
    #   sentry-sdk
charset-normalizer==3.3.2
    # via requests
click==8.1.7
    # via
    #   ray
    #   typer
    #   uvicorn
cloudpathlib==0.16.0
    # via weasel
cloudpickle==3.0.0
    # via outlines
cmake==3.29.3
    # via vllm
confection==0.1.4
    # via
    #   thinc
    #   weasel
cymem==2.0.8
    # via
    #   preshed
    #   spacy
    #   thinc
deprecation==2.1.0
    # via postgrest
diskcache==5.6.3
    # via outlines
distro==1.9.0
    # via openai
en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl
    # via -r requirements/requirements.in
exceptiongroup==1.2.0
    # via anyio
fastapi==0.109.2
    # via
    #   -r requirements/requirements.in
    #   sentry-sdk
    #   vllm
filelock==3.13.1
    # via
    #   huggingface-hub
    #   ray
    #   torch
    #   transformers
    #   triton
    #   vllm
frozenlist==1.4.1
    # via
    #   aiohttp
    #   aiosignal
    #   ray
fsspec==2023.12.2
    # via
    #   huggingface-hub
    #   torch
gcld3==3.0.13
    # via -r requirements/requirements.in
gensim==4.3.2
    # via -r requirements/requirements.in
gotrue==2.1.0
    # via supabase
h11==0.14.0
    # via
    #   httpcore
    #   uvicorn
httpcore==0.17.3
    # via httpx
httptools==0.6.1
    # via uvicorn
httpx==0.24.1
    # via
    #   -r requirements/requirements.in
    #   gotrue
    #   openai
    #   postgrest
    #   storage3
    #   supabase
    #   supafunc
huggingface-hub==0.23.2
    # via
    #   tokenizers
    #   transformers
idna==3.6
    # via
    #   anyio
    #   httpx
    #   requests
    #   yarl
interegular==0.3.3
    # via
    #   lm-format-enforcer
    #   outlines
jinja2==3.1.2
    # via
    #   outlines
    #   spacy
    #   torch
joblib==1.4.2
    # via outlines
jsonschema==4.20.0
    # via
    #   outlines
    #   ray
jsonschema-specifications==2023.11.2
    # via jsonschema
langcodes==3.3.0
    # via spacy
lark==1.1.9
    # via outlines
llvmlite==0.42.0
    # via numba
lm-format-enforcer==0.10.1
    # via vllm
markupsafe==2.1.3
    # via jinja2
mpmath==1.3.0
    # via sympy
msgpack==1.0.7
    # via ray
multidict==6.0.5
    # via
    #   aiohttp
    #   yarl
murmurhash==1.0.10
    # via
    #   preshed
    #   spacy
    #   thinc
nest-asyncio==1.6.0
    # via outlines
networkx==3.2.1
    # via torch
ninja==1.11.1.1
    # via vllm
numba==0.59.1
    # via outlines
numpy==1.26.2
    # via
    #   blis
    #   gensim
    #   numba
    #   outlines
    #   scipy
    #   spacy
    #   thinc
    #   transformers
    #   vllm
    #   xformers
nvidia-cublas-cu12==12.1.3.1
    # via
    #   nvidia-cudnn-cu12
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cuda-cupti-cu12==12.1.105
    # via torch
nvidia-cuda-nvrtc-cu12==12.1.105
    # via torch
nvidia-cuda-runtime-cu12==12.1.105
    # via torch
nvidia-cudnn-cu12==8.9.2.26
    # via torch
nvidia-cufft-cu12==11.0.2.54
    # via torch
nvidia-curand-cu12==10.3.2.106
    # via torch
nvidia-cusolver-cu12==11.4.5.107
    # via torch
nvidia-cusparse-cu12==12.1.0.106
    # via
    #   nvidia-cusolver-cu12
    #   torch
nvidia-ml-py==12.555.43
    # via vllm
nvidia-nccl-cu12==2.20.5
    # via torch
nvidia-nvjitlink-cu12==12.5.40
    # via
    #   nvidia-cusolver-cu12
    #   nvidia-cusparse-cu12
nvidia-nvtx-cu12==12.1.105
    # via torch
openai==1.30.5
    # via vllm
outlines==0.0.34
    # via vllm
packaging==23.2
    # via
    #   deprecation
    #   huggingface-hub
    #   lm-format-enforcer
    #   ray
    #   spacy
    #   thinc
    #   transformers
    #   weasel
postgrest==0.13.0
    # via supabase
preshed==3.0.9
    # via
    #   spacy
    #   thinc
prometheus-client==0.20.0
    # via
    #   prometheus-fastapi-instrumentator
    #   vllm
prometheus-fastapi-instrumentator==7.0.0
    # via vllm
protobuf==3.20.3
    # via
    #   -r requirements/requirements.in
    #   ray
psutil==5.9.7
    # via vllm
py-cpuinfo==9.0.0
    # via vllm
pydantic==2.6.2
    # via
    #   -r requirements/requirements.in
    #   confection
    #   fastapi
    #   gotrue
    #   lm-format-enforcer
    #   openai
    #   outlines
    #   postgrest
    #   spacy
    #   thinc
    #   vllm
    #   weasel
pydantic-core==2.16.3
    # via pydantic
python-dateutil==2.8.2
    # via
    #   realtime
    #   storage3
python-dotenv==1.0.0
    # via uvicorn
pyyaml==6.0.1
    # via
    #   huggingface-hub
    #   lm-format-enforcer
    #   ray
    #   transformers
    #   uvicorn
ray==2.9.3
    # via vllm
realtime==1.0.2
    # via supabase
referencing==0.32.0
    # via
    #   jsonschema
    #   jsonschema-specifications
    #   outlines
regex==2023.10.3
    # via
    #   tiktoken
    #   transformers
requests==2.31.0
    # via
    #   huggingface-hub
    #   outlines
    #   ray
    #   spacy
    #   tiktoken
    #   transformers
    #   vllm
    #   weasel
    #   youtube-transcript-api
rpds-py==0.14.2
    # via
    #   jsonschema
    #   referencing
safetensors==0.4.1
    # via transformers
scipy==1.12.0
    # via
    #   -r requirements/requirements.in
    #   gensim
    #   outlines
sentencepiece==0.1.99
    # via vllm
sentry-sdk[fastapi]==1.39.1
    # via -r requirements/requirements.in
six==1.16.0
    # via python-dateutil
smart-open==6.4.0
    # via
    #   gensim
    #   spacy
    #   weasel
sniffio==1.3.0
    # via
    #   anyio
    #   httpcore
    #   httpx
    #   openai
spacy==3.7.2
    # via
    #   -r requirements/requirements.in
    #   en-core-web-sm
spacy-legacy==3.0.12
    # via spacy
spacy-loggers==1.0.5
    # via spacy
srsly==2.4.8
    # via
    #   confection
    #   spacy
    #   thinc
    #   weasel
starlette==0.36.3
    # via
    #   fastapi
    #   prometheus-fastapi-instrumentator
storage3==0.7.0
    # via supabase
strenum==0.4.15
    # via postgrest
supabase==2.3.0
    # via -r requirements/requirements.in
supafunc==0.3.1
    # via supabase
sympy==1.12
    # via torch
thinc==8.2.2
    # via spacy
tiktoken==0.7.0
    # via vllm
tokenizers==0.19.1
    # via
    #   transformers
    #   vllm
torch==2.3.0+cu121
    # via
    #   -r requirements/requirements.in
    #   outlines
    #   vllm
    #   vllm-flash-attn
    #   xformers
tqdm==4.66.1
    # via
    #   huggingface-hub
    #   openai
    #   spacy
    #   transformers
transformers==4.41.2
    # via
    #   -r requirements/requirements.in
    #   outlines
    #   vllm
triton==2.3.0
    # via torch
typer==0.9.0
    # via
    #   spacy
    #   weasel
typing-extensions==4.9.0
    # via
    #   cloudpathlib
    #   fastapi
    #   huggingface-hub
    #   openai
    #   pydantic
    #   pydantic-core
    #   realtime
    #   storage3
    #   torch
    #   typer
    #   uvicorn
    #   vllm
urllib3==2.1.0
    # via
    #   requests
    #   sentry-sdk
uvicorn[standard]==0.24.0.post1
    # via vllm
uvloop==0.19.0
    # via uvicorn
vllm==0.4.3
    # via -r requirements/requirements.in
vllm-flash-attn==2.5.8.post2
    # via vllm
wasabi==1.1.2
    # via
    #   spacy
    #   thinc
    #   weasel
watchfiles==0.21.0
    # via uvicorn
weasel==0.3.4
    # via spacy
websockets==11.0.3
    # via
    #   realtime
    #   uvicorn
xformers==0.0.26.post1
    # via vllm
yarl==1.9.4
    # via aiohttp
youtube-transcript-api==0.6.1
    # via -r requirements/requirements.in

# The following packages are considered to be unsafe in a requirements file:
# setuptools
